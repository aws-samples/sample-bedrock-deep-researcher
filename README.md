# AI-Powered Article Generation with Bedrock Deep Research

Bedrock Deep Research is a Streamlit-based application using Amazon Bedrock, LangGraph, and LangChain AWS libraries that automates article/report generation through AI-powered research, content writing, and image generation. It combines web research, structured content generation, and human feedback to produce comprehensive, well-researched articles with accompanying header images (generated by [Amazon Bedrock Nova Canvas](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html)). This repo is inspired by LangChain's [Deep Researcher](https://github.com/langchain-ai/open_deep_research/tree/main).

## Repository Structure
```
bedrock_deep_research/
├── bedrock_deep_research.py          # Main Streamlit application entry point
├── bedrock_deep_research/
│   ├── config.py             # Configuration settings and parameters
│   ├── graph.py              # Core workflow orchestration using LangGraph
│   ├── model.py              # Data models for articles and sections
│   ├── nodes/                # Individual workflow components
│   │   ├── article_head_image_generator.py    # Header image generation
│   │   ├── article_outline_generator.py       # Article outline creation
│   │   ├── section_writer.py                  # Section content generation
│   │   └── [other node files]                 # Additional workflow components
│   ├── utils.py              # Utility functions
│   └── web_search.py         # Web research integration using Tavily API
├── poetry.lock               # Poetry dependency lock file
└── pyproject.toml           # Project configuration and dependencies
```


### Prerequisites
- Python 3.12 (to install, visit this link: https://www.python.org/downloads/).
   Check your python version using `python --version`.
   If your global python isn't set as `3.12`, follow the steps here: https://python-poetry.org/docs/managing-environments/)
- Poetry for dependency management
- [AWS Bedrock access](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html) for LLM inference (supported models provided in `SUPPORTED_MODELS` variable in `./bedrock_deep_research/config.py`)


## Setup

The setup is meant to be used locally with [AWS authentication](https://docs.aws.amazon.com/cli/v1/userguide/cli-authentication-short-term.html), as well as within Amazon Sagemaker: either in [JupyterLab](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-jl.html) or [Code Editor](https://docs.aws.amazon.com/sagemaker/latest/dg/code-editor.html) instance.

### 1. Installation
```bash
# Clone the repository
git clone https://github.com/aws-samples/bedrock-deep-research.git
cd bedrock-deep-research

# Activate the virtual environment
poetry shell

# Install dependencies using Poetry
poetry install
```

### 2. Create and set your Tavily API key

Go to https://app.tavily.com/home and create an API KEY for free. Copy the API Key and paste it into the `env.tmp` file.

### 3. Setup the environment variables

Copy the environment variables into the local environment.
```
cp env.tmp .env
```

### 4. Run the application

- Start the Streamlit application:
```bash
streamlit run bedrock_deep_research.py
```

- In the web interface:
   - Enter your article topic
   - Specify writing guidelines
   - Configure search parameters
   - Click "Generate Outline"

- Review and provide feedback on the outline:
   - Submit feedback to refine the outline
   - Accept the outline to proceed with full article generation

- Once complete:
   - Review the generated article with header image
   - Copy to clipboard or start a new article

### Configuration details

**Writing Guideline samples:**
You could include instructions like:
```text
- Strict 150-200 word limit
- Start with your most important insight in **bold**
- Include code examples where relevant
- Focus on practical implementation
```

**Web Research Configuration:**
```python
number_of_queries = 2  # Number of search queries per section
max_search_depth = 2   # Maximum research iterations per section
```

**Debug Mode:**
```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
streamlit run bedrock_deep_research.py
```

## Data Flow
The application follows a sequential workflow from topic input to final article generation, with feedback loops for refinement.

Key Components of the graph:
- Initial Researcher: It performs initial web searches to gather context
- Article Outline Generator: creates structured outline using research data
- Human Feedback Provider: This incorporates human feedback for the outline
- Section Writer: A subgraph that generates content after web research.
- Header Image Generator: creates relevant header images
- Final compilation: combines all elements into a cohesive article


### Contributing
Contributions are welcome! Please open an issue or submit a pull request if you have any improvements or bug fixes. Read CONTRIBUTING.md for more details.


### License
This library is licensed under the MIT-0 License. See the LICENSE file.